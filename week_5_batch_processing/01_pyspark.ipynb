{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:28:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "        .appName('test') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download data\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006794 fhvhv_tripdata_2021-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Show number observations\n",
    "!wc -l fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option('header', 'true') \\\n",
    "        .option('inferSchema', 'true') \\\n",
    "            .parquet('fhvhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|airport_fee|tips|driver_pay|shared_request_flag|shared_match_flag|access_a_ride_flag|wav_request_flag|wav_match_flag|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|           HV0003|              B02682|              B02682|2021-01-01 00:28:09|2021-01-01 00:31:42|2021-01-01 00:33:44|2021-01-01 00:49:07|         230|         166|      5.26|      923|              22.28|  0.0|0.67|     1.98|                2.75|       null| 0.0|     14.99|                  N|                N|                  |               N|             N|\n",
      "|           HV0003|              B02682|              B02682|2021-01-01 00:45:56|2021-01-01 00:55:19|2021-01-01 00:55:19|2021-01-01 01:18:21|         152|         167|      3.65|     1382|              18.36|  0.0|0.55|     1.63|                 0.0|       null| 0.0|     17.06|                  N|                N|                  |               N|             N|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime=datetime.datetime(2021, 1, 1, 0, 28, 9), on_scene_datetime=datetime.datetime(2021, 1, 1, 0, 31, 42), pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, trip_miles=5.26, trip_time=923, base_passenger_fare=22.28, tolls=0.0, bcf=0.67, sales_tax=1.98, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=14.99, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime=datetime.datetime(2021, 1, 1, 0, 45, 56), on_scene_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, trip_miles=3.65, trip_time=1382, base_passenger_fare=18.36, tolls=0.0, bcf=0.55, sales_tax=1.63, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=17.06, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', TimestampType(), True), StructField('on_scene_datetime', TimestampType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data with custom schema\n",
    "# from pyspark.sql import types\n",
    "# schema = types.StructType(\n",
    "#     [\n",
    "#         types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "#         types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "#         types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "#         types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "#         types.StructField('PULocationID', types.IntegerType(), True),\n",
    "#         types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "#         types.StructField('SR_Flag', types.StringType(), True)\n",
    "#     ]\n",
    "# )\n",
    "# df = spark.read \\\n",
    "#     .option(\"header\", \"true\") \\\n",
    "#     .schema(schema) \\\n",
    "#     .csv('fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 24 partitions\n",
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save data to parquet format, the result will have 24 explicit partitions data\n",
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the partitions of parquet files\n",
    "df = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-11 18:40:22|2021-01-11 19:15:49|         262|         231|\n",
      "|2021-01-05 15:13:22|2021-01-05 15:27:50|          61|         181|\n",
      "|2021-01-31 18:42:09|2021-01-31 18:59:52|         232|           4|\n",
      "|2021-01-27 22:24:36|2021-01-27 22:26:43|          68|          68|\n",
      "|2021-01-30 08:35:46|2021-01-30 08:39:42|         256|         255|\n",
      "|2021-01-16 02:25:35|2021-01-16 02:34:21|          89|          91|\n",
      "|2021-01-11 11:58:23|2021-01-11 12:14:19|          97|          61|\n",
      "|2021-01-03 07:44:58|2021-01-03 08:04:45|          26|         178|\n",
      "|2021-01-14 18:52:00|2021-01-14 19:19:00|         181|         198|\n",
      "|2021-01-08 20:35:35|2021-01-08 21:06:33|          76|          91|\n",
      "|2021-01-15 13:49:48|2021-01-15 14:35:23|         246|          16|\n",
      "|2021-01-27 10:37:56|2021-01-27 10:53:35|         135|          73|\n",
      "|2021-01-11 17:29:44|2021-01-11 17:42:49|          68|         211|\n",
      "|2021-01-24 21:32:15|2021-01-24 21:52:42|         249|         236|\n",
      "|2021-01-26 18:03:39|2021-01-26 18:10:53|          79|           4|\n",
      "|2021-01-07 08:05:32|2021-01-07 08:30:47|          22|          25|\n",
      "|2021-01-12 17:16:00|2021-01-12 17:25:56|          69|         119|\n",
      "|2021-01-16 21:00:39|2021-01-16 21:18:15|         239|         239|\n",
      "|2021-01-14 23:35:14|2021-01-14 23:45:30|          61|          62|\n",
      "|2021-01-17 23:23:11|2021-01-17 23:34:42|         241|          20|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select some columns and filter the conditions\n",
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark built-in functions\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2021-01-11|  2021-01-11|         262|         231|\n",
      "| 2021-01-05|  2021-01-05|          61|         181|\n",
      "| 2021-01-02|  2021-01-02|         100|           1|\n",
      "| 2021-01-31|  2021-01-31|         232|           4|\n",
      "| 2021-01-05|  2021-01-05|         162|           1|\n",
      "| 2021-01-27|  2021-01-27|          68|          68|\n",
      "| 2021-01-18|  2021-01-18|         205|         205|\n",
      "| 2021-01-30|  2021-01-30|         256|         255|\n",
      "| 2021-01-16|  2021-01-16|          89|          91|\n",
      "| 2021-01-05|  2021-01-05|         132|         102|\n",
      "| 2021-01-11|  2021-01-11|          97|          61|\n",
      "| 2021-01-22|  2021-01-22|          79|          37|\n",
      "| 2021-01-03|  2021-01-03|          26|         178|\n",
      "| 2021-01-14|  2021-01-14|         181|         198|\n",
      "| 2021-01-08|  2021-01-08|          76|          91|\n",
      "| 2021-01-15|  2021-01-15|         246|          16|\n",
      "| 2021-01-27|  2021-01-27|         135|          73|\n",
      "| 2021-01-18|  2021-01-18|          74|         234|\n",
      "| 2021-01-11|  2021-01-11|          68|         211|\n",
      "| 2021-01-24|  2021-01-24|         249|         236|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new columns (convert the datetime column to date format)\n",
    "df.withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "        .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions with UDF\n",
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'\n",
    "\n",
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+------------+------------+\n",
      "|base_id|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "|  e/acc| 2021-01-11|  2021-01-11|         262|         231|\n",
      "|  e/a39| 2021-01-05|  2021-01-05|          61|         181|\n",
      "|  e/9ce| 2021-01-02|  2021-01-02|         100|           1|\n",
      "|  e/b42| 2021-01-31|  2021-01-31|         232|           4|\n",
      "|  s/af0| 2021-01-05|  2021-01-05|         162|           1|\n",
      "|  a/b43| 2021-01-27|  2021-01-27|          68|          68|\n",
      "|  e/9ce| 2021-01-18|  2021-01-18|         205|         205|\n",
      "|  e/b35| 2021-01-30|  2021-01-30|         256|         255|\n",
      "|  e/b3b| 2021-01-16|  2021-01-16|          89|          91|\n",
      "|  e/9ce| 2021-01-05|  2021-01-05|         132|         102|\n",
      "|  e/acc| 2021-01-11|  2021-01-11|          97|          61|\n",
      "|  e/9ce| 2021-01-22|  2021-01-22|          79|          37|\n",
      "|  e/b32| 2021-01-03|  2021-01-03|          26|         178|\n",
      "|  a/b49| 2021-01-14|  2021-01-14|         181|         198|\n",
      "|  e/acc| 2021-01-08|  2021-01-08|          76|          91|\n",
      "|  e/b3c| 2021-01-15|  2021-01-15|         246|          16|\n",
      "|  s/b36| 2021-01-27|  2021-01-27|         135|          73|\n",
      "|  e/9ce| 2021-01-18|  2021-01-18|          74|         234|\n",
      "|  e/a39| 2021-01-11|  2021-01-11|          68|         211|\n",
      "|  e/b3f| 2021-01-24|  2021-01-24|         249|         236|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "        .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "            .select('base_id','pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
